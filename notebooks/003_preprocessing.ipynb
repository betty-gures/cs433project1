{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0887c483",
   "metadata": {},
   "source": [
    "# 003: Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f23c4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import helpers\n",
    "from preprocessing import preprocess\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5c4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = helpers.load_csv_data(\"../data/dataset\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618ae164",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_orig = x_train.copy()\n",
    "x_test_orig = x_test.copy()\n",
    "y_train_orig = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a587549",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_orig.copy()\n",
    "x_test = x_test_orig.copy()\n",
    "y_train = y_train_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a506e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and parse missing values\n",
    "missing_values = []\n",
    "with open(\"../data/missing_values.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().strip('\"')  # remove whitespace and surrounding quotes\n",
    "        # split by comma and convert to int\n",
    "        numbers = [int(x.strip()) for x in line.split(\",\") if x.strip() != \"\"]\n",
    "        missing_values.append(numbers)\n",
    "\n",
    "assert x_train.shape[1] == len(missing_values), \"Mismatch between features and missing values\"\n",
    "\n",
    "# replace missing values with np.nan\n",
    "for col, miss_vals in enumerate(missing_values):\n",
    "    for miss_val in miss_vals:\n",
    "        x_train[x_train[:, col] == miss_val, col] = np.nan\n",
    "        x_test[x_test[:, col] == miss_val, col] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787d49e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 53 unique values\n",
      "Feature 34: 5 unique values\n",
      "Feature 51: 7 unique values\n",
      "Feature 53: 4 unique values\n",
      "Feature 58: 9 unique values\n",
      "Feature 88: 76 unique values\n",
      "Feature 91: 77 unique values\n",
      "Feature 102: 12 unique values\n",
      "Feature 106: 10 unique values\n",
      "Feature 119: 16 unique values\n",
      "Feature 122: 14 unique values\n",
      "Feature 125: 7 unique values\n",
      "Feature 130: 9 unique values\n",
      "Feature 182: 3 unique values\n",
      "Feature 189: 6 unique values\n",
      "Feature 190: 5 unique values\n",
      "Feature 191: 7 unique values\n",
      "Feature 194: 5 unique values\n",
      "Feature 196: 5 unique values\n",
      "Feature 198: 5 unique values\n",
      "Feature 201: 7 unique values\n",
      "Feature 216: 8 unique values\n",
      "Feature 217: 4 unique values\n",
      "Feature 218: 5 unique values\n",
      "Feature 224: 8 unique values\n",
      "Feature 225: 8 unique values\n",
      "Feature 227: 3 unique values\n",
      "Feature 239: 9 unique values\n",
      "Feature 240: 8 unique values\n",
      "Feature 242: 9 unique values\n",
      "Feature 243: 3 unique values\n",
      "Feature 244: 6 unique values\n",
      "Feature 245: 6 unique values\n",
      "Feature 282: 3 unique values\n",
      "Feature 283: 3 unique values\n",
      "Feature 313: 4 unique values\n",
      "Feature 314: 4 unique values\n",
      "Feature 315: 5 unique values\n"
     ]
    }
   ],
   "source": [
    "# recoding of nominal and maybe others -> one-hot encoding\n",
    "variable_type = []\n",
    "with open(\"../data/variable_type.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        variable_type.append(line.strip().strip('\"')) # remove whitespace and surrounding quotes\n",
    "\n",
    "nominal_features = np.where(np.array(variable_type)==\"nominal\")[0]\n",
    "one_hot_encoded = []\n",
    "for idx in nominal_features:\n",
    "    unique_vals = np.unique(x_train[:, idx])\n",
    "    print(f\"Feature {idx}: {len(unique_vals)} unique values\")\n",
    "    if len(unique_vals) < 50:\n",
    "        train_cols = [(x_train[:, idx] == val).astype(float) for val in unique_vals if val != np.nan]\n",
    "        test_cols = [(x_test[:, idx] == val).astype(float) for val in unique_vals if val != np.nan]\n",
    "        x_train = np.column_stack([x_train, *train_cols])\n",
    "        x_test = np.column_stack([x_test, *test_cols])\n",
    "        one_hot_encoded.append(idx)\n",
    "# Delete the original columns\n",
    "#x_train = np.delete(x_train, np.array(one_hot_encoded), axis=1)\n",
    "#x_test = np.delete(x_test, np.array(one_hot_encoded), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae79d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value imputation\n",
    "# TODO: try other strategies\n",
    "# Mean imputation for each column in x_train\n",
    "def impute_missing_values(x):\n",
    "    col_means = np.nanmean(x, axis=0)\n",
    "    inds = np.where(np.isnan(x))\n",
    "    x[inds] = np.take(col_means, inds[1])\n",
    "    return x\n",
    "x_train = impute_missing_values(x_train)\n",
    "x_test = impute_missing_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91a46ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kick out features with no variance in training or test set\n",
    "stds_train = np.std(x_train, axis=0)\n",
    "stds_test = np.std(x_test, axis=0)\n",
    "x_train = x_train[:, (stds_train > 0) & (stds_test > 0)]\n",
    "x_test = x_test[:, (stds_train > 0) & (stds_test > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5905eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling by standardization\n",
    "x_train = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "x_test = (x_test - x_train.mean(axis=0)) / x_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d1d6d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (y_train + 1) / 2  # convert to 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "919e1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.c_[np.ones((y_train.shape[0], 1)), x_train] # add bias term\n",
    "x_test = np.c_[np.ones((x_test.shape[0], 1)), x_test] # add bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e9bc97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"../data/dataset_prep/train.npz\", x_train=x_train, y_train=y_train)\n",
    "np.savez(\"../data/dataset_prep/test.npz\", x_test=x_test, test_ids=test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae324bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Replacing missing value codes with np.nan...\n",
      "Saving preprocessed data to ../data/dataset_prep/...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[5.3000000e+01, 1.1000000e+01, 1.1162015e+07, ...,           nan,\n",
       "                   nan, 2.0000000e+00],\n",
       "        [3.3000000e+01, 1.2000000e+01, 1.2152015e+07, ...,           nan,\n",
       "                   nan,           nan],\n",
       "        [2.0000000e+01, 1.0000000e+01, 1.0202015e+07, ..., 1.0000000e+00,\n",
       "         2.0000000e+00, 2.0000000e+00],\n",
       "        ...,\n",
       "        [3.9000000e+01, 1.0000000e+01, 1.0202015e+07, ..., 2.0000000e+00,\n",
       "         2.0000000e+00, 2.0000000e+00],\n",
       "        [3.3000000e+01, 1.2000000e+01, 1.2302015e+07, ...,           nan,\n",
       "                   nan, 2.0000000e+00],\n",
       "        [3.2000000e+01, 9.0000000e+00, 9.1220150e+06, ...,           nan,\n",
       "                   nan, 2.0000000e+00]]),\n",
       " array([[4.4000000e+01, 2.0000000e+00, 2.0820150e+06, ..., 1.0000000e+00,\n",
       "         1.0000000e+00, 2.0000000e+00],\n",
       "        [2.7000000e+01, 1.0000000e+00, 1.1920150e+06, ...,           nan,\n",
       "                   nan, 2.0000000e+00],\n",
       "        [3.5000000e+01, 5.0000000e+00, 5.2620150e+06, ..., 1.0000000e+00,\n",
       "         1.0000000e+00, 2.0000000e+00],\n",
       "        ...,\n",
       "        [9.0000000e+00, 1.1000000e+01, 1.1272015e+07, ...,           nan,\n",
       "                   nan,           nan],\n",
       "        [1.5000000e+01, 1.2000000e+01, 1.2122015e+07, ..., 1.0000000e+00,\n",
       "         1.0000000e+00, 2.0000000e+00],\n",
       "        [4.5000000e+01, 1.2000000e+01, 1.2282015e+07, ...,           nan,\n",
       "                   nan, 2.0000000e+00]]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([328135, 328136, 328137, ..., 437511, 437512, 437513]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(one_hot_encoding=False, save_dir=\"../data/dataset_prep/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
