{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8685e1",
   "metadata": {},
   "source": [
    "# 006: Running ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b1d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from preprocessing import preprocess\n",
    "from models import OrdinaryLeastSquares, LogisticRegression\n",
    "from model_selection import cross_validation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33df1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_jsonl(obj, path):\n",
    "    \"\"\"Append a dataclass (or dict) as one JSON line to a file.\"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        obj = asdict(obj)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765883e",
   "metadata": {},
   "source": [
    "# Preprocessing ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b1f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_preprocessing_ablation(kwarg_list, num_samples = int(1e5), num_folds = 5):\n",
    "    mean_f1 = []\n",
    "\n",
    "    for cv_kw in kwarg_list:\n",
    "        print(\"Running with args:\", cv_kw)\n",
    "        x_train, _, y_train, _ = preprocess(**cv_kw)\n",
    "        \n",
    "        cv_results = cross_validation(x_train[:num_samples], y_train[:num_samples], num_folds=num_folds, verbose=False, model_class=LogisticRegression)\n",
    "        mean_f1.append(np.mean(cv_results.f1_scores))\n",
    "\n",
    "    for i, (cv_kw, mean) in enumerate(zip(kwarg_list, mean_f1)):\n",
    "        print(cv_kw)\n",
    "        print(f\"{mean - mean_f1[0]}\" if i > 0 else mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0100a",
   "metadata": {},
   "source": [
    "## replace_nan_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a8ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with args: {'replace_nan_codes': True}\n",
      "Replacing missing value codes with np.nan...\n",
      "Applying one-hot encoding...\n",
      "Imputing missing values...\n",
      "Removing invariant features...\n",
      "Starting fold 1/5 with 80000 samples\n",
      "Starting fold 2/5 with 80000 samples\n",
      "Starting fold 3/5 with 80000 samples\n",
      "Starting fold 4/5 with 80000 samples\n",
      "Starting fold 5/5 with 80000 samples\n",
      "Running with args: {'replace_nan_codes': False}\n",
      "Applying one-hot encoding...\n",
      "Imputing missing values...\n",
      "Removing invariant features...\n",
      "Starting fold 1/5 with 80000 samples\n",
      "Starting fold 2/5 with 80000 samples\n",
      "Starting fold 3/5 with 80000 samples\n",
      "Starting fold 4/5 with 80000 samples\n",
      "Starting fold 5/5 with 80000 samples\n",
      "{'replace_nan_codes': True}\n",
      "0.3735032352696262\n",
      "{'replace_nan_codes': False}\n",
      "-0.013057384818908724\n"
     ]
    }
   ],
   "source": [
    "kwarg_list = [{\"replace_nan_codes\": True}, {\"replace_nan_codes\": False}]\n",
    "run_preprocessing_ablation(kwarg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8887d1",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566bc5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with args: {'one_hot_encoding': True}\n",
      "Replacing missing value codes with np.nan...\n",
      "Applying one-hot encoding...\n",
      "Imputing missing values...\n",
      "Removing invariant features...\n",
      "Starting fold 1/5 with 8000 samples\n",
      "Starting fold 2/5 with 8000 samples\n",
      "Starting fold 3/5 with 8000 samples\n",
      "Starting fold 4/5 with 8000 samples\n",
      "Starting fold 5/5 with 8000 samples\n",
      "Running with args: {'one_hot_encoding': False}\n",
      "Replacing missing value codes with np.nan...\n",
      "Imputing missing values...\n",
      "Removing invariant features...\n",
      "Starting fold 1/5 with 8000 samples\n",
      "Starting fold 2/5 with 8000 samples\n",
      "Starting fold 3/5 with 8000 samples\n",
      "Starting fold 4/5 with 8000 samples\n",
      "Starting fold 5/5 with 8000 samples\n",
      "{'one_hot_encoding': True}\n",
      "0.35612664992698134\n",
      "{'one_hot_encoding': False}\n",
      "0.006440710033129238\n"
     ]
    }
   ],
   "source": [
    "kwarg_list = [{\"one_hot_encoding\": True}, {\"one_hot_encoding\": False}]\n",
    "run_preprocessing_ablation(kwarg_list, num_samples = int(1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1955f",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8037e9f",
   "metadata": {},
   "source": [
    "# Model ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b00e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing missing value codes with np.nan...\n",
      "Applying one-hot encoding...\n",
      "Imputing missing values...\n",
      "Removing invariant features...\n"
     ]
    }
   ],
   "source": [
    "x_train, _, y_train = preprocess() # fixed data\n",
    "def run_model_ablation(kwarg_list, num_samples = int(1e5), num_folds = 5):\n",
    "    mean_f1 = []\n",
    "\n",
    "    for cv_kw in kwarg_list:\n",
    "        print(\"Running with args:\", cv_kw)\n",
    "        cv_results = cross_validation(x_train[:num_samples], y_train[:num_samples], num_folds=num_folds, verbose=False, model_class=LogisticRegression,**cv_kw)\n",
    "        mean_f1.append(np.mean(cv_results.f1_scores))\n",
    "\n",
    "    for i, (cv_kw, mean) in enumerate(zip(kwarg_list, mean_f1)):\n",
    "        print(cv_kw)\n",
    "        print(f\"{mean - mean_f1[0]}\" if i > 0 else mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64005472",
   "metadata": {},
   "source": [
    "## Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with args: {'weighting': True}\n",
      "Starting fold 1/5 with 8000 samples\n",
      "Starting fold 2/5 with 8000 samples\n",
      "Starting fold 3/5 with 8000 samples\n",
      "Starting fold 4/5 with 8000 samples\n",
      "Starting fold 5/5 with 8000 samples\n",
      "Running with args: {'weighting': False}\n",
      "Starting fold 1/5 with 8000 samples\n",
      "Starting fold 2/5 with 8000 samples\n",
      "Starting fold 3/5 with 8000 samples\n",
      "Starting fold 4/5 with 8000 samples\n",
      "Starting fold 5/5 with 8000 samples\n",
      "{'weighting': True}\n",
      "0.36511378008378675\n",
      "{'weighting': False}\n",
      "0.005183613279058474\n"
     ]
    }
   ],
   "source": [
    "kwarg_list = [{\"weighting\": True}, {\"weighting\": False}]\n",
    "run_model_ablation(kwarg_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
