{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ff706e",
   "metadata": {},
   "source": [
    "# 005: Cross Validate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8110fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from models import OrdinaryLeastSquares, LogisticRegression, LinearSVM, KNearestNeighbors\n",
    "from model_selection import cross_validation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b58a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(\"../data/dataset_prep/train.npz\")\n",
    "x_train, y_train = train[\"x_train\"], train[\"y_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d7fc1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 721)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958bc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(cv_results):\n",
    "    print(f\"Average F1-score: {np.mean(cv_results.f1_scores)*100:.1f}% ± {np.std(cv_results.f1_scores)*100:.1f}\")\n",
    "    print(f\"Average F2-score: {np.mean(cv_results.f2_scores)*100:.1f}% ± {np.std(cv_results.f2_scores)*100:.1f}\")\n",
    "    print(f\"Average AUC-ROC: {np.mean(cv_results.auc_rocs)*100:.1f}% ± {np.std(cv_results.auc_rocs)*100:.1f}\")\n",
    "    print(f\" & {np.mean(cv_results.f1_scores)*100:.1f}±{np.std(cv_results.f1_scores)*100:.1f} & \"\n",
    "          f\"{np.mean(cv_results.f2_scores)*100:.1f}±{np.std(cv_results.f2_scores)*100:.1f} & \"\n",
    "          f\"{np.mean(cv_results.auc_rocs)*100:.1f}±{np.std(cv_results.auc_rocs)*100:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06903609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating model: LinearSVM\n",
      "Starting fold 1/5 with 8000 samples\n",
      "Early stopping at iteration 140\n",
      "Early stopping at iteration 22\n",
      "Early stopping at iteration 155\n",
      "Early stopping at iteration 24\n",
      "Early stopping at iteration 249\n",
      "Early stopping at iteration 50\n",
      "Early stopping at iteration 153\n",
      "Early stopping at iteration 31\n",
      "Early stopping at iteration 122\n",
      "Early stopping at iteration 11\n",
      "Fold 1 - F1: 0.0111731843575419, F2: 0.007132667617689015, AUC-ROC: 0.7674113381425389\n",
      "Starting fold 2/5 with 8000 samples\n",
      "Early stopping at iteration 202\n",
      "Early stopping at iteration 34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross-validating model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel[\u001b[33m'\u001b[39m\u001b[33mmodel_class\u001b[39m\u001b[33m'\u001b[39m].\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m num_samples = \u001b[38;5;28mint\u001b[39m(\u001b[32m1e4\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m model[\u001b[33m'\u001b[39m\u001b[33mmodel_class\u001b[39m\u001b[33m'\u001b[39m] != KNearestNeighbors \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[32m1e4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m cv_results = \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m print_results(cv_results)\n\u001b[32m     15\u001b[39m out_dir = \u001b[33m\"\u001b[39m\u001b[33m../results\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/glandorf/cs433project1/notebooks/../model_selection.py:70\u001b[39m, in \u001b[36mcross_validation\u001b[39m\u001b[34m(x_train, y_train, model_class, num_folds, seed, verbose, scoring_groups, max_test, **model_args)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_idx.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m model = model_class(**model_args) \u001b[38;5;66;03m# initialize a new model for each fold\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m model.train(x_train[train_idx], y_train[train_idx]) \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[32m     72\u001b[39m y_probs = model.predict(x_train[val_idx], save_scores=\u001b[38;5;28;01mTrue\u001b[39;00m, scores=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/glandorf/cs433project1/notebooks/../models.py:406\u001b[39m, in \u001b[36mhyperparameter_tuning\u001b[39m\u001b[34m(self, X, y, metric, verbose)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/glandorf/cs433project1/notebooks/../models.py:355\u001b[39m, in \u001b[36mhinge_loss\u001b[39m\u001b[34m(y, X, w, _lambda, include_reg)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28mself\u001b[39m.patience = patience\n\u001b[32m    354\u001b[39m \u001b[38;5;66;03m# model parameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m \u001b[38;5;28mself\u001b[39m.w = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_settings = [\n",
    "    #{\"model_class\": OrdinaryLeastSquares},\n",
    "    #{\"model_class\": LogisticRegression},\n",
    "    {\"model_class\": LinearSVM},\n",
    "    #{\"model_class\": KNearestNeighbors, \"use_pca\": True},\n",
    "]\n",
    "for model in model_settings:\n",
    "    print(f\"Cross-validating model: {model['model_class'].__name__}\")\n",
    "    num_samples = int(1e4) if model['model_class'] != KNearestNeighbors else int(1e4)\n",
    "    cv_results = cross_validation(x_train[:num_samples], y_train[:num_samples], verbose=True, **model)\n",
    "    print_results(cv_results)\n",
    "\n",
    "    out_dir = \"../results\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{model['model_class'].__name__}.txt\")\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(f\"Model: {model['model_class'].__name__}\\n\\n\")\n",
    "        f.write(\"cv_results repr:\\n\")\n",
    "        f.write(repr(cv_results))\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"Aggregated metrics:\\n\")\n",
    "        f.write(f\"Average F1-score: {np.mean(cv_results.f1_scores)*100:.1f}% ± {np.std(cv_results.f1_scores)*100:.1f}\\n\")\n",
    "        f.write(f\"Average F2-score: {np.mean(cv_results.f2_scores)*100:.1f}% ± {np.std(cv_results.f2_scores)*100:.1f}\\n\")\n",
    "        f.write(f\"Average AUC-ROC: {np.mean(cv_results.auc_rocs)*100:.1f}% ± {np.std(cv_results.auc_rocs)*100:.1f}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ec324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-score: 42.8% ± 0.3\n",
      "Average F2-score: 50.1% ± 0.6\n",
      "Average AUC-ROC: 86.1% ± 0.1\n",
      " & 42.8±0.3 & 50.1±0.6 & 86.1±0.1\n"
     ]
    }
   ],
   "source": [
    "print_results(cv_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
